{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import  torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scSEBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sse = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.cse = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels//2, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels//2, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        sse_out = self.sse(x)*x\n",
    "        cse_out = self.cse(x)*x\n",
    "        return torch.max(sse_out, cse_out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_UNet_scSE(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Encoder path\n",
    "        self.encoder = nn.ModuleDict({\n",
    "            \"conv1\":nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu),\n",
    "            \"maxpool\": resnet.maxpool,\n",
    "            \"layer1\": resnet.layer1,\n",
    "            \"layer2\": resnet.layer2,\n",
    "            \"layer3\": resnet.layer3,\n",
    "            \"layer4\": resnet.layer4          })\n",
    "        \n",
    "        #scSE blocks for skip connection\n",
    "        self.scSE_skip1 = scSEBlock(64) # for conv1 output\n",
    "        self.scSE_skip2 = scSEBlock(64) # for layer1 output\n",
    "        self.scSE_skip3 = scSEBlock(128) # for layer2 output\n",
    "        self.scSE_skip4 = scSEBlock(256) # for layer3 output\n",
    "\n",
    "        # Decoder path\n",
    "        self.upconv1 = self.upconv(512, 256)\n",
    "        self.dec_conv1 = nn.Conv2d(512, 256, kernel_size=1) # 256 from encoder and 256 from decoder\n",
    "\n",
    "        self.upconv2 = self.upconv(256, 128)\n",
    "        self.dec_conv2 = nn.Conv2d(256, 128, kernel_size=1) # 128 from encoder and 128 from decoder\n",
    "\n",
    "        self.upconv3 = self.upconv(128, 64)\n",
    "        self.dec_conv3 = nn.Conv2d(128, 64, kernel_size=1) # 64 from encoder and 64 from decoder\n",
    "\n",
    "        self.upconv4 = self.upconv(64, 32)\n",
    "        self.dec_conv4 = nn.Conv2d(96, 32, kernel_size=1) # 32 from decoder and 64 from encoder\n",
    "\n",
    "        self.final_upsample = nn.ConvTranspose2d(32, 32, kernel_size=1)\n",
    "        self.final_conv = nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def upconv(self, in_channels, out_channels):\n",
    "\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder['conv1'](x) # 64 channel\n",
    "        print('x1 shape: ', x1.shape)\n",
    "\n",
    "        x2 = self.encoder['maxpool'](x1)\n",
    "        print('x2 shape:', x2.shape)\n",
    "\n",
    "        x3 = self.encoder['layer1'](x2) # 128 channel\n",
    "        print('x3 shape:', x3.shape)\n",
    "\n",
    "        x4 = self.encoder['layer2'](x3) # 256 channel\n",
    "        print('x4 shape:', x4.shape)\n",
    "\n",
    "        x5 = self.encoder['layer3'](x4)\n",
    "        print ('x5 shape:', x5.shape)\n",
    "\n",
    "        x6 = self.encoder['layer4'](x5)\n",
    "        print('x6 shape:', x6.shape)\n",
    "\n",
    "        # Decoder path with scSE blocks applied to skip connection\n",
    "        # First Upsampling blocks\n",
    "        d1 = self.upconv1(x6)\n",
    "        x5_scse = self.scSE_skip4(x5)\n",
    "        d1 = torch.cat([d1, x5_scse], dim=1) # 256+256 = 512 channels\n",
    "        d1 = self.dec_conv1(d1) # 512 -> 256 channels\n",
    "\n",
    "        d2 = self.upconv2(d1)  # 128 channles\n",
    "        x4_scse = self.scSE_skip3(x4)\n",
    "        d2 = torch.cat([d2, x4_scse], dim=1) # 128 + 128 = 256 channels\n",
    "        d2 = self.dec_conv2(d2) # 256 -> 128 channels\n",
    "\n",
    "\n",
    "        d3 = self.upconv3(d2)         # 64 channels\n",
    "        x3_scse = self.scSE_skip2(x3)\n",
    "        d3 = torch.cat([d3, x3_scse], dim=1) # 64 +64 = 128 channels\n",
    "        d3 = self.dec_conv3(d3)                 # 128 _> 64 channels\n",
    "\n",
    "        d4 = self.upconv4(d3)            # 32 channels\n",
    "        x1_scse = self.scSE_skip1(x1) # 32 + 64 = 96 channels\n",
    "        d4 = torch.cat([d4, x1_scse], dim=1)\n",
    "        d4 = self.dec_conv4(d4) # 96 -> 32 channels\n",
    "\n",
    "        # Final upsampling and convolution\n",
    "        d5 = self.final_upsample(d4)\n",
    "        out = self.final_conv(d5)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape:  torch.Size([1, 64, 128, 128])\n",
      "x2 shape: torch.Size([1, 64, 64, 64])\n",
      "x3 shape: torch.Size([1, 64, 64, 64])\n",
      "x4 shape: torch.Size([1, 128, 32, 32])\n",
      "x5 shape: torch.Size([1, 256, 16, 16])\n",
      "x6 shape: torch.Size([1, 512, 8, 8])\n",
      "torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18_UNet_scSE(num_classes=1)\n",
    "x = torch.randn(1, 3, 256, 256)\n",
    "output = model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
